{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from path import Path\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import seaborn as sns; sns.set()\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = 'Resources/mbti_clean.csv'\n",
    "df = pd.read_csv(data)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def remove_stopwords(post):\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    words = [word.lower() for word in tokenizer.tokenize(post)]\n",
    "    words = [word for word in words if word not in stopwords.words('english')]\n",
    "    return np.array(words)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[\"posts\"].apply(remove_stopwords).values\n",
    "y = df[\"type\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(212844,)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "   y,  random_state=1, stratify=y)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(212844,)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 2.37, NNZs: 14941, Bias: -1.033359, T: 212844, Avg. loss: 0.048840\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.77, NNZs: 17988, Bias: -1.018973, T: 425688, Avg. loss: 0.046179\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1.56, NNZs: 20614, Bias: -1.014455, T: 638532, Avg. loss: 0.045925\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1.44, NNZs: 22669, Bias: -1.011746, T: 851376, Avg. loss: 0.045825\n",
      "Total training time: 0.17 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1.36, NNZs: 24441, Bias: -1.011005, T: 1064220, Avg. loss: 0.045771\n",
      "Total training time: 0.22 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1.31, NNZs: 25909, Bias: -1.009314, T: 1277064, Avg. loss: 0.045735\n",
      "Total training time: 0.27 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1.27, NNZs: 27182, Bias: -1.008287, T: 1489908, Avg. loss: 0.045712\n",
      "Total training time: 0.31 seconds.\n",
      "Convergence after 7 epochs took 0.31 seconds\n",
      "-- Epoch 1\n",
      "Norm: 4.05, NNZs: 32812, Bias: -1.030255, T: 212844, Avg. loss: 0.169603\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 3.09, NNZs: 39627, Bias: -1.014787, T: 425688, Avg. loss: 0.159389\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 2.75, NNZs: 44817, Bias: -1.009701, T: 638532, Avg. loss: 0.158485\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2.57, NNZs: 48906, Bias: -1.007578, T: 851376, Avg. loss: 0.158124\n",
      "Total training time: 0.16 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2.45, NNZs: 52090, Bias: -1.005736, T: 1064220, Avg. loss: 0.157921\n",
      "Total training time: 0.21 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 2.37, NNZs: 54583, Bias: -1.005476, T: 1277064, Avg. loss: 0.157801\n",
      "Total training time: 0.25 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 2.30, NNZs: 56589, Bias: -1.005089, T: 1489908, Avg. loss: 0.157712\n",
      "Total training time: 0.30 seconds.\n",
      "Convergence after 7 epochs took 0.30 seconds\n",
      "-- Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 2.60, NNZs: 17764, Bias: -1.027145, T: 212844, Avg. loss: 0.057174\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.97, NNZs: 21585, Bias: -1.017055, T: 425688, Avg. loss: 0.054107\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1.73, NNZs: 24705, Bias: -1.012171, T: 638532, Avg. loss: 0.053819\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1.60, NNZs: 27118, Bias: -1.010454, T: 851376, Avg. loss: 0.053702\n",
      "Total training time: 0.15 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1.52, NNZs: 29172, Bias: -1.009775, T: 1064220, Avg. loss: 0.053637\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1.46, NNZs: 30837, Bias: -1.008565, T: 1277064, Avg. loss: 0.053597\n",
      "Total training time: 0.23 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1.42, NNZs: 32199, Bias: -1.006889, T: 1489908, Avg. loss: 0.053570\n",
      "Total training time: 0.28 seconds.\n",
      "Convergence after 7 epochs took 0.28 seconds\n",
      "-- Epoch 1\n",
      "Norm: 4.11, NNZs: 34747, Bias: -1.025801, T: 212844, Avg. loss: 0.165579\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 3.15, NNZs: 41949, Bias: -1.014089, T: 425688, Avg. loss: 0.156204\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2.80, NNZs: 47263, Bias: -1.008060, T: 638532, Avg. loss: 0.155333\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2.60, NNZs: 51151, Bias: -1.007767, T: 851376, Avg. loss: 0.154994\n",
      "Total training time: 0.16 seconds.\n",
      "-- Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 2.48, NNZs: 54205, Bias: -1.006455, T: 1064220, Avg. loss: 0.154789\n",
      "Total training time: 0.20 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 2.40, NNZs: 56661, Bias: -1.004248, T: 1277064, Avg. loss: 0.154669\n",
      "Total training time: 0.25 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 2.34, NNZs: 58678, Bias: -1.003304, T: 1489908, Avg. loss: 0.154588\n",
      "Total training time: 0.29 seconds.\n",
      "Convergence after 7 epochs took 0.29 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1.28, NNZs: 5460, Bias: -1.051883, T: 212844, Avg. loss: 0.010895\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.00, NNZs: 6513, Bias: -1.027055, T: 425688, Avg. loss: 0.010248\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    1.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 0.88, NNZs: 7465, Bias: -1.020841, T: 638532, Avg. loss: 0.010196\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.81, NNZs: 8262, Bias: -1.017800, T: 851376, Avg. loss: 0.010176\n",
      "Total training time: 0.15 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.77, NNZs: 8990, Bias: -1.015230, T: 1064220, Avg. loss: 0.010164\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.74, NNZs: 9611, Bias: -1.012812, T: 1277064, Avg. loss: 0.010157\n",
      "Total training time: 0.22 seconds.\n",
      "Convergence after 6 epochs took 0.23 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1.24, NNZs: 5658, Bias: -1.033707, T: 212844, Avg. loss: 0.009364\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.97, NNZs: 6925, Bias: -1.021443, T: 425688, Avg. loss: 0.008920\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.86, NNZs: 8083, Bias: -1.015983, T: 638532, Avg. loss: 0.008877\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.80, NNZs: 9057, Bias: -1.013948, T: 851376, Avg. loss: 0.008859\n",
      "Total training time: 0.16 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.77, NNZs: 9837, Bias: -1.011436, T: 1064220, Avg. loss: 0.008850\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.74, NNZs: 10599, Bias: -1.010620, T: 1277064, Avg. loss: 0.008844\n",
      "Total training time: 0.23 seconds.\n",
      "Convergence after 6 epochs took 0.23 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1.27, NNZs: 5617, Bias: -1.038036, T: 212844, Avg. loss: 0.009371\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.99, NNZs: 6787, Bias: -1.021855, T: 425688, Avg. loss: 0.008869\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.88, NNZs: 7912, Bias: -1.016396, T: 638532, Avg. loss: 0.008828\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.82, NNZs: 8835, Bias: -1.013633, T: 851376, Avg. loss: 0.008809\n",
      "Total training time: 0.15 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.78, NNZs: 9707, Bias: -1.013008, T: 1064220, Avg. loss: 0.008800\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.76, NNZs: 10363, Bias: -1.011294, T: 1277064, Avg. loss: 0.008794\n",
      "Total training time: 0.23 seconds.\n",
      "Convergence after 6 epochs took 0.23 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1.67, NNZs: 9163, Bias: -1.031483, T: 212844, Avg. loss: 0.020172\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.29, NNZs: 11171, Bias: -1.020995, T: 425688, Avg. loss: 0.019182\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1.14, NNZs: 12838, Bias: -1.015011, T: 638532, Avg. loss: 0.019089\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1.06, NNZs: 14292, Bias: -1.013652, T: 851376, Avg. loss: 0.019048\n",
      "Total training time: 0.17 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1.01, NNZs: 15448, Bias: -1.011895, T: 1064220, Avg. loss: 0.019026\n",
      "Total training time: 0.21 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.97, NNZs: 16406, Bias: -1.010545, T: 1277064, Avg. loss: 0.019013\n",
      "Total training time: 0.26 seconds.\n",
      "Convergence after 6 epochs took 0.26 seconds\n",
      "-- Epoch 1\n",
      "Norm: 7.82, NNZs: 54274, Bias: -1.017343, T: 212844, Avg. loss: 0.378734\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 6.73, NNZs: 64411, Bias: -1.012495, T: 425688, Avg. loss: 0.356688\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 6.38, NNZs: 70576, Bias: -1.004107, T: 638532, Avg. loss: 0.354697\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 6.21, NNZs: 74718, Bias: -1.004421, T: 851376, Avg. loss: 0.353892\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 6.08, NNZs: 77623, Bias: -1.002735, T: 1064220, Avg. loss: 0.353424\n",
      "Total training time: 0.22 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 6.01, NNZs: 79662, Bias: -1.000303, T: 1277064, Avg. loss: 0.353175\n",
      "Total training time: 0.28 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 5.95, NNZs: 81212, Bias: -0.999911, T: 1489908, Avg. loss: 0.352976\n",
      "Total training time: 0.33 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 5.92, NNZs: 82413, Bias: -1.000212, T: 1702752, Avg. loss: 0.352860\n",
      "Total training time: 0.38 seconds.\n",
      "Convergence after 8 epochs took 0.39 seconds\n",
      "-- Epoch 1\n",
      "Norm: 9.05, NNZs: 60723, Bias: -1.020574, T: 212844, Avg. loss: 0.453013\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 7.96, NNZs: 71132, Bias: -1.011106, T: 425688, Avg. loss: 0.427299\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 7.67, NNZs: 76858, Bias: -1.004836, T: 638532, Avg. loss: 0.424980\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 7.50, NNZs: 80401, Bias: -1.003042, T: 851376, Avg. loss: 0.423946\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 7.39, NNZs: 82621, Bias: -1.001355, T: 1064220, Avg. loss: 0.423434\n",
      "Total training time: 0.23 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 7.31, NNZs: 84235, Bias: -0.999480, T: 1277064, Avg. loss: 0.423071\n",
      "Total training time: 0.28 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 7.26, NNZs: 85371, Bias: -0.998358, T: 1489908, Avg. loss: 0.422857\n",
      "Total training time: 0.34 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 7.21, NNZs: 86257, Bias: -0.997328, T: 1702752, Avg. loss: 0.422710\n",
      "Total training time: 0.39 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 7.18, NNZs: 86959, Bias: -0.996960, T: 1915596, Avg. loss: 0.422569\n",
      "Total training time: 0.44 seconds.\n",
      "Convergence after 9 epochs took 0.44 seconds\n",
      "-- Epoch 1\n",
      "Norm: 5.11, NNZs: 44697, Bias: -1.018075, T: 212844, Avg. loss: 0.265818\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 3.93, NNZs: 53642, Bias: -1.007236, T: 425688, Avg. loss: 0.250205\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 3.50, NNZs: 59555, Bias: -1.004316, T: 638532, Avg. loss: 0.248805\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 3.27, NNZs: 63880, Bias: -1.004482, T: 851376, Avg. loss: 0.248237\n",
      "Total training time: 0.16 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 3.12, NNZs: 66813, Bias: -1.002343, T: 1064220, Avg. loss: 0.247919\n",
      "Total training time: 0.20 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 3.02, NNZs: 69267, Bias: -1.001331, T: 1277064, Avg. loss: 0.247724\n",
      "Total training time: 0.24 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 2.94, NNZs: 71124, Bias: -1.000583, T: 1489908, Avg. loss: 0.247590\n",
      "Total training time: 0.29 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 2.88, NNZs: 72559, Bias: -1.000729, T: 1702752, Avg. loss: 0.247491\n",
      "Total training time: 0.34 seconds.\n",
      "Convergence after 8 epochs took 0.34 seconds\n",
      "-- Epoch 1\n",
      "Norm: 6.24, NNZs: 51180, Bias: -1.008734, T: 212844, Avg. loss: 0.317181\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 5.01, NNZs: 61061, Bias: -1.007567, T: 425688, Avg. loss: 0.299167\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 4.59, NNZs: 67189, Bias: -1.004224, T: 638532, Avg. loss: 0.297498\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 4.37, NNZs: 71293, Bias: -0.999384, T: 851376, Avg. loss: 0.296820\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 4.23, NNZs: 74118, Bias: -1.000614, T: 1064220, Avg. loss: 0.296474\n",
      "Total training time: 0.24 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 4.14, NNZs: 76203, Bias: -0.999392, T: 1277064, Avg. loss: 0.296230\n",
      "Total training time: 0.29 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 4.07, NNZs: 77820, Bias: -0.998456, T: 1489908, Avg. loss: 0.296073\n",
      "Total training time: 0.34 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 4.01, NNZs: 79091, Bias: -0.998749, T: 1702752, Avg. loss: 0.295956\n",
      "Total training time: 0.39 seconds.\n",
      "Convergence after 8 epochs took 0.39 seconds\n",
      "-- Epoch 1\n",
      "Norm: 2.21, NNZs: 13542, Bias: -1.034533, T: 212844, Avg. loss: 0.041011\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.68, NNZs: 16312, Bias: -1.019339, T: 425688, Avg. loss: 0.038700\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1.48, NNZs: 18536, Bias: -1.016499, T: 638532, Avg. loss: 0.038497\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1.37, NNZs: 20467, Bias: -1.013766, T: 851376, Avg. loss: 0.038413\n",
      "Total training time: 0.15 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1.30, NNZs: 22076, Bias: -1.010397, T: 1064220, Avg. loss: 0.038368\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1.24, NNZs: 23411, Bias: -1.009808, T: 1277064, Avg. loss: 0.038339\n",
      "Total training time: 0.22 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1.21, NNZs: 24482, Bias: -1.008826, T: 1489908, Avg. loss: 0.038319\n",
      "Total training time: 0.27 seconds.\n",
      "Convergence after 7 epochs took 0.27 seconds\n",
      "-- Epoch 1\n",
      "Norm: 2.56, NNZs: 17696, Bias: -1.031161, T: 212844, Avg. loss: 0.061147\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.95, NNZs: 21440, Bias: -1.019305, T: 425688, Avg. loss: 0.057634\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1.71, NNZs: 24499, Bias: -1.014875, T: 638532, Avg. loss: 0.057327\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1.59, NNZs: 26966, Bias: -1.011193, T: 851376, Avg. loss: 0.057196\n",
      "Total training time: 0.17 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1.50, NNZs: 29079, Bias: -1.009744, T: 1064220, Avg. loss: 0.057127\n",
      "Total training time: 0.21 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1.45, NNZs: 30746, Bias: -1.008152, T: 1277064, Avg. loss: 0.057084\n",
      "Total training time: 0.25 seconds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 7\n",
      "Norm: 1.40, NNZs: 32223, Bias: -1.007073, T: 1489908, Avg. loss: 0.057052\n",
      "Total training time: 0.30 seconds.\n",
      "Convergence after 7 epochs took 0.30 seconds\n",
      "-- Epoch 1\n",
      "Norm: 2.45, NNZs: 16327, Bias: -1.032141, T: 212844, Avg. loss: 0.050202\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.86, NNZs: 19827, Bias: -1.017368, T: 425688, Avg. loss: 0.047559\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1.63, NNZs: 22657, Bias: -1.012759, T: 638532, Avg. loss: 0.047310\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1.51, NNZs: 25064, Bias: -1.010985, T: 851376, Avg. loss: 0.047204\n",
      "Total training time: 0.15 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1.43, NNZs: 26908, Bias: -1.009094, T: 1064220, Avg. loss: 0.047150\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1.38, NNZs: 28628, Bias: -1.007813, T: 1277064, Avg. loss: 0.047109\n",
      "Total training time: 0.23 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1.35, NNZs: 29970, Bias: -1.006787, T: 1489908, Avg. loss: 0.047087\n",
      "Total training time: 0.28 seconds.\n",
      "Convergence after 7 epochs took 0.28 seconds\n",
      "-- Epoch 1\n",
      "Norm: 2.98, NNZs: 21514, Bias: -1.024692, T: 212844, Avg. loss: 0.078313\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 2.25, NNZs: 26129, Bias: -1.019790, T: 425688, Avg. loss: 0.074115\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1.98, NNZs: 29651, Bias: -1.014466, T: 638532, Avg. loss: 0.073716\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1.83, NNZs: 32449, Bias: -1.009887, T: 851376, Avg. loss: 0.073553\n",
      "Total training time: 0.15 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1.74, NNZs: 34692, Bias: -1.007777, T: 1064220, Avg. loss: 0.073462\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1.67, NNZs: 36547, Bias: -1.007944, T: 1277064, Avg. loss: 0.073409\n",
      "Total training time: 0.24 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1.62, NNZs: 38087, Bias: -1.006244, T: 1489908, Avg. loss: 0.073367\n",
      "Total training time: 0.28 seconds.\n",
      "Convergence after 7 epochs took 0.28 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  16 out of  16 | elapsed:    4.9s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn import (datasets, feature_extraction, pipeline, linear_model,\n",
    "metrics, model_selection, feature_selection)\n",
    "\n",
    "text_clf_svm = pipeline.Pipeline([('vect', feature_extraction.text.CountVectorizer(tokenizer=lambda doc: doc, lowercase=False)),\n",
    "                         ('tfidf', feature_extraction.text.TfidfTransformer()),\n",
    "                         ('chi2', feature_selection.SelectKBest(feature_selection.chi2, k = 'all')),\n",
    "                         ('clf', linear_model.SGDClassifier(random_state=42, verbose = 5)),\n",
    "                        ])\n",
    "\n",
    "text_clf_svm = text_clf_svm.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.547941\n",
      "Test set score: 0.247984\n",
      "Test error rate: 0.752016\n",
      "Number of mislabeled points out of a total 70948 points for the Linear SVM algorithm: 53354\n"
     ]
    }
   ],
   "source": [
    "predicted_svm = text_clf_svm.predict(X_test)\n",
    "print(\"Training set score: %f\" % text_clf_svm.score(X_train, y_train))\n",
    "print(\"Test set score: %f\" % text_clf_svm.score(X_test, y_test))\n",
    "print(\"Test error rate: %f\" % (1 - text_clf_svm.score(X_test, y_test)))\n",
    "print(\"Number of mislabeled points out of a total %d points for the Linear SVM algorithm: %d\"\n",
    "% (X_test.shape[0],(y_test != predicted_svm).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>ENTP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>INTJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>ISFP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>INFJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>INFP</td>\n",
       "      <td>INTP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Prediction Actual\n",
       "0       ENTP   ENTP\n",
       "1       INFJ   INTJ\n",
       "2       INFJ   ISFP\n",
       "3       INTJ   INFJ\n",
       "4       INFP   INTP"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = predicted_svm\n",
    "results = pd.DataFrame({\n",
    "   \"Prediction\": y_pred,\n",
    "   \"Actual\": y_test\n",
    "}).reset_index(drop=True)\n",
    "results.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24798443930766195"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ENFJ       0.11      0.09      0.10      1620\n",
      "        ENFP       0.20      0.15      0.17      5590\n",
      "        ENTJ       0.09      0.08      0.09      1899\n",
      "        ENTP       0.19      0.17      0.18      5481\n",
      "        ESFJ       0.03      0.04      0.04       360\n",
      "        ESFP       0.02      0.02      0.02       314\n",
      "        ESTJ       0.05      0.05      0.05       313\n",
      "        ESTP       0.09      0.05      0.07       674\n",
      "        INFJ       0.29      0.28      0.28     12604\n",
      "        INFP       0.31      0.43      0.36     15146\n",
      "        INTJ       0.23      0.22      0.22      8777\n",
      "        INTP       0.26      0.26      0.26     10518\n",
      "        ISFJ       0.15      0.10      0.12      1359\n",
      "        ISFP       0.11      0.08      0.09      2022\n",
      "        ISTJ       0.12      0.07      0.09      1670\n",
      "        ISTP       0.13      0.12      0.12      2601\n",
      "\n",
      "    accuracy                           0.25     70948\n",
      "   macro avg       0.15      0.14      0.14     70948\n",
      "weighted avg       0.24      0.25      0.24     70948\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, y_pred)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False,\n",
    "            xticklabels=df.type,\n",
    "            yticklabels=df.type)\n",
    "plt.xlabel('true label')\n",
    "plt.ylabel('predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
